eval:
  enabled: False
  # use this to evaluate the model over longer rollouts, every so many validation batches
  rollout: 12
  frequency: 5
  spread_skill_bin: 101
plot:
  enabled: True
  frequency: 750
  sample_idx: 0
  per_sample: 6
  parameters:
    23: t_850
    72: z_500
    # 10: q_850
    # 36: u_850
    # 49: v_850
    # 75: z_850
    # 83: 2t
    # 81: 10u
    # 82: 10v
    # 79: msl
  learned_features: True

debug:
  # this will detect and trace back NaNs / Infs etc. but will slow down training
  anomaly_detection: False

# activate the pytorch profiler (disable this in production)
# remember to also activate the tensorboard logger (below)
profiler: False

checkpoint:
  every_n_minutes: 15 # Approximate, as this is checked at the end of training steps
  every_n_epochs: 1
  every_n_train_steps: 1000 # Does not scale with rollout

log:
  wandb:
    enabled: True
    offline: False
    log_model: False
    # logger options (these probably come with some overhead)
    gradients: False
    parameters: False
  tensorboard:
    enabled: False
  interval: 100
