eval:
  enabled: False
  # use this to evaluate the model over longer rollouts, every so many validation batches
  rollout: 12
  frequency: 20
plot:
  enabled: True
  frequency: 750
  sample_idx: 0
  per_sample: 6
  parameters:
    - z_500
    - t_850
    - u_850
    - v_850
    - 2t
    - 10u
    - 10v
    - sp
    - tp
    - sd
  learned_features: True

debug:
  # this will detect and trace back NaNs / Infs etc. but will slow down training
  anomaly_detection: False

# activate the pytorch profiler (disable this in production)
# remember to also activate the tensorboard logger (below)
profiler: False

checkpoint:
  every_n_minutes: 15 # Approximate, as this is checked at the end of training steps
  every_n_epochs: 1
  every_n_train_steps: 1000 # Does not scale with rollout

log:
  wandb:
    enabled: True
    offline: False
    log_model: False
    # logger options (these probably come with some overhead)
    gradients: False
    parameters: False
  tensorboard:
    enabled: False
  interval: 100
  code:
    level: "DEBUG"
