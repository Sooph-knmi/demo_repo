{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import h3\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData \n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ERA_NEIGHBORS = 9\n",
    "\n",
    "# https://h3geo.org/docs/core-library/restable/\n",
    "# h3_0 : 122 cells\n",
    "# h3_1:  842 cells\n",
    "# h3_2: 5882 cells\n",
    "\n",
    "NUM_H33_NEIGHBORS = 7\n",
    "NUM_H32_NEIGHBORS = 7\n",
    "NUM_H31_NEIGHBORS = 7\n",
    "NUM_H30_NEIGHBORS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_res = 96\n",
    "era = xr.open_dataset(f\"/ec/res4/hpcperm/syma/gnn/o96/sfc_o{era_res}_19880401.grib\", engine=\"cfgrib\")\n",
    "era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import contains_isolated_nodes, from_scipy_sparse_matrix\n",
    "\n",
    "def create_self_mapping(coords_sp, num_neighbors, src_label, dest_label, area_weights=None):\n",
    "    neigh = NearestNeighbors(n_neighbors=num_neighbors, metric=\"haversine\", n_jobs=4)\n",
    "    neigh.fit(coords_sp)\n",
    "    adjmat = neigh.kneighbors_graph(coords_sp, num_neighbors, mode=\"distance\").tocoo()\n",
    "    print(f\"adjmat.shape = {adjmat.shape}\")\n",
    "    adjmat_norm = normalize(adjmat, norm=\"l1\", axis=1)\n",
    "    adjmat_norm.data = 1.0 - adjmat_norm.data\n",
    "\n",
    "    has_isolated = contains_isolated_nodes(from_scipy_sparse_matrix(adjmat_norm)[0])\n",
    "    assert not has_isolated, \"OOPS! You're left with some dangling nodes ... revisit your mapping\"\n",
    "\n",
    "    map_key = (src_label, \"to\", dest_label)\n",
    "\n",
    "    map_gdata = {\n",
    "        \"edge_index\": torch.from_numpy(np.stack([adjmat.col, adjmat.row], axis=0).astype(np.int64)),\n",
    "        \"edge_attr\": torch.from_numpy(np.expand_dims(adjmat_norm.data, axis=-1).astype(np.float32)),\n",
    "        # source and dest coords are the same, keep duplicates (makes the data structure a bit easier to use)\n",
    "        \"scoords_rad\": torch.from_numpy(coords_sp.astype(np.float32)),\n",
    "        \"dcoords_rad\": torch.from_numpy(coords_sp.astype(np.float32)),\n",
    "        \"info\": f\"{src_label}_to_{dest_label} graph\",\n",
    "    }\n",
    "\n",
    "    if area_weights is not None:\n",
    "        map_gdata['area_weights'] = torch.from_numpy(np.array(area_weights))\n",
    "\n",
    "    return map_key, map_gdata, neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_era_weights():\n",
    "    area_weights = []\n",
    "    nind = 0\n",
    "    nlon = 20\n",
    "    tlat = era_res\n",
    "    mlon = 4*tlat+16\n",
    "    for i in range(tlat):\n",
    "        area = np.cos(np.deg2rad(era.latitude[nind].data))*mlon/nlon\n",
    "        area_weights.extend([area]*nlon)\n",
    "        #print(era.latitude[nind].data,era.longitude[nind].data,area)\n",
    "        nind+=nlon\n",
    "        nlon+=4\n",
    "    area_weights.extend(area_weights[::-1])\n",
    "    assert(len(area_weights)==era.latitude.size)\n",
    "    return area_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(get_era_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elat = np.array(era[\"latitude\"])\n",
    "elon = np.array(era[\"longitude\"])\n",
    "ecoords = np.stack([elat, elon], axis=-1).reshape((-1, 2))\n",
    "ecoords_sp = np.deg2rad(ecoords)\n",
    "print(f\"ecoords_sp.shape = {ecoords_sp.shape}\")\n",
    "\n",
    "area_weights = get_era_weights()\n",
    "\n",
    "era2era_key, era2era_gdata, eneigh = create_self_mapping(ecoords_sp, NUM_ERA_NEIGHBORS, \"era\", \"era\", area_weights=area_weights)\n",
    "print(era2era_key, list(era2era_gdata.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h3_coords(resolution):\n",
    "    h3_grid = [h3.geo_to_h3(lat, lon, resolution) for lat, lon in ecoords]\n",
    "    h3_grid = sorted(set(h3_grid))\n",
    "    hcoords = np.array([h3.h3_to_geo(val) for val in h3_grid])\n",
    "    hcoords_sp = np.deg2rad(hcoords)\n",
    "    return hcoords_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h33_coords = get_h3_coords(resolution=3)\n",
    "h33_2_h33_key, h33_2_h33_gdata, h33neigh = create_self_mapping(h33_coords, NUM_H33_NEIGHBORS, \"h33\", \"h33\", area_weights=None)\n",
    "print(h33_2_h33_key, list(h33_2_h33_gdata.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h32_coords = get_h3_coords(resolution=2)\n",
    "h32_2_h32_key, h32_2_h32_gdata, h32neigh = create_self_mapping(h32_coords, NUM_H32_NEIGHBORS, \"h32\", \"h32\", area_weights=None)\n",
    "print(h32_2_h32_key, list(h32_2_h32_gdata.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h31_coords = get_h3_coords(resolution=1)\n",
    "h31_2_h31_key, h31_2_h31_gdata, h31neigh = create_self_mapping(h31_coords, NUM_H31_NEIGHBORS, \"h31\", \"h31\", area_weights=None)\n",
    "print(h31_2_h31_key, list(h31_2_h31_gdata.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h30_coords = get_h3_coords(resolution=0)\n",
    "h30_2_h30_key, h30_2_h30_gdata, h30neigh = create_self_mapping(h30_coords, NUM_H30_NEIGHBORS, \"h30\", \"h30\", area_weights=None)\n",
    "print(h30_2_h30_key, list(h30_2_h30_gdata.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cross_mapping(src_nn, src_coords_sp, dst_coords_sp, src_label, dest_label, hdist_cutoff=200.):\n",
    "    RADIUS_EARTH = 6371\n",
    "    # print(f\"using cut-off radius of {H_CUTOFF}\")\n",
    "    RADIUS_SRC_TO_DST = hdist_cutoff / RADIUS_EARTH\n",
    "\n",
    "    src_to_dest_adjmat = src_nn.radius_neighbors_graph(\n",
    "        dst_coords_sp,\n",
    "        radius=RADIUS_SRC_TO_DST,\n",
    "    ).tocoo()   \n",
    "\n",
    "    src_to_dest_adjmat_norm = normalize(src_to_dest_adjmat, norm=\"l1\", axis=1)\n",
    "    src_to_dest_adjmat_norm.data = 1.0 - src_to_dest_adjmat_norm.data\n",
    "    map_key = (src_label, \"to\", dest_label)\n",
    "\n",
    "    has_isolated = contains_isolated_nodes(from_scipy_sparse_matrix(src_to_dest_adjmat_norm)[0])\n",
    "    assert not has_isolated, \"OOPS! You're left with some dangling nodes ... revisit your mapping\"\n",
    "\n",
    "    map_gdata = {\n",
    "        \"edge_index\": torch.from_numpy(np.stack([src_to_dest_adjmat.col, src_to_dest_adjmat.row], axis=0).astype(np.int64)),\n",
    "        \"edge_attr\": torch.from_numpy(np.expand_dims(src_to_dest_adjmat_norm.data, axis=-1).astype(np.float32)),\n",
    "        \"scoords_rad\": torch.from_numpy(src_coords_sp.astype(np.float32)),\n",
    "        \"dcoords_rad\": torch.from_numpy(dst_coords_sp.astype(np.float32)),\n",
    "        \"info\": f\"{src_label}_to_{dest_label} graph\",\n",
    "    }\n",
    "\n",
    "    if area_weights is not None:\n",
    "        map_gdata['area_weights'] = torch.from_numpy(np.array(area_weights))\n",
    "\n",
    "    return map_key, map_gdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates (in radians)\n",
    "h33_coords_sp = h33_2_h33_gdata[\"scoords_rad\"].numpy()\n",
    "h32_coords_sp = h32_2_h32_gdata[\"scoords_rad\"].numpy()\n",
    "h31_coords_sp = h31_2_h31_gdata[\"scoords_rad\"].numpy()\n",
    "h30_coords_sp = h30_2_h30_gdata[\"scoords_rad\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-mappings\n",
    "# era-to-h33\n",
    "era_2_h33_key, era_2_h33_gdata = create_cross_mapping(eneigh, ecoords_sp, h33_coords_sp, \"era\", \"h33\")\n",
    "print(era_2_h33_key, list(era_2_h33_gdata.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h33-to-h32\n",
    "h33_2_h32_key, h33_2_h32_gdata = create_cross_mapping(h33neigh, h33_coords_sp, h32_coords_sp, \"h33\", \"h32\", hdist_cutoff=200.)\n",
    "print(h33_2_h32_key, list(h33_2_h32_gdata.keys()))\n",
    "\n",
    "# h32-to-h31\n",
    "h32_2_h31_key, h32_2_h31_gdata = create_cross_mapping(h32neigh, h32_coords_sp, h31_coords_sp, \"h32\", \"h31\", hdist_cutoff=350.)\n",
    "print(h32_2_h31_key, list(h32_2_h31_gdata.keys()))\n",
    "\n",
    "# h31-to-h30\n",
    "h31_2_h30_key, h31_2_h30_gdata = create_cross_mapping(h31neigh, h31_coords_sp, h30_coords_sp, \"h31\", \"h30\", hdist_cutoff=1000.)\n",
    "print(h31_2_h30_key, list(h31_2_h30_gdata.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_graph_data = HeteroData(\n",
    "    {\n",
    "        era2era_key: era2era_gdata,\n",
    "        h33_2_h33_key: h33_2_h33_gdata,\n",
    "        h32_2_h32_key: h32_2_h32_gdata,\n",
    "        h31_2_h31_key: h31_2_h31_gdata,\n",
    "        h30_2_h30_key: h30_2_h30_gdata,\n",
    "        # cross-mappings\n",
    "        era_2_h33_key: era_2_h33_gdata,\n",
    "        h33_2_h32_key: h33_2_h32_gdata,\n",
    "        h32_2_h31_key: h32_2_h31_gdata,\n",
    "        h31_2_h30_key: h31_2_h30_gdata,\n",
    "    }\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aifs.utils.graph_gen import directional_edge_features, directional_edge_features_rotated\n",
    "\n",
    "luse_rotated_edge_features = True\n",
    "\n",
    "if luse_rotated_edge_features:\n",
    "    edge_directions_func = directional_edge_features_rotated # relative to target node rotated to north pole\n",
    "else:\n",
    "    edge_directions_func = directional_edge_features # loc target node - loc source node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h_ in [\"h33\", \"h32\", \"h31\", \"h30\"]:\n",
    "\n",
    "    hhedge_dirs = []\n",
    "    for n in range(critic_graph_data[(h_, \"to\", h_)]['edge_index'].shape[1]):\n",
    "        i,j = critic_graph_data[(h_, \"to\", h_)]['edge_index'][:,n]\n",
    "        ic = critic_graph_data[(h_, \"to\", h_)]['scoords_rad'][i,:]\n",
    "        jc = critic_graph_data[(h_, \"to\", h_)]['dcoords_rad'][j,:]\n",
    "        hhedge_dirs.append(edge_directions_func(ic, jc))\n",
    "        \n",
    "    hhedge_dirs = torch.from_numpy(np.stack(hhedge_dirs).astype(np.float32))\n",
    "    hhedge_attr = torch.concat([critic_graph_data[(h_, \"to\", h_)]['edge_attr'], hhedge_dirs], axis=-1)\n",
    "    critic_graph_data[(h_, \"to\", h_)]['edge_attr'] = hhedge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = [\"era\", \"h33\", \"h32\", \"h31\", \"h30\"]\n",
    "\n",
    "for s_, d_ in zip(meshes[:-1], meshes[1:]):\n",
    "\n",
    "    hhedge_dirs = []\n",
    "    for n in range(critic_graph_data[(s_, \"to\", d_)]['edge_index'].shape[1]):\n",
    "        i,j = critic_graph_data[(s_, \"to\", d_)]['edge_index'][:,n]\n",
    "        ic = critic_graph_data[(s_, \"to\", d_)]['scoords_rad'][i,:]\n",
    "        jc = critic_graph_data[(s_, \"to\", d_)]['dcoords_rad'][j,:]\n",
    "        hhedge_dirs.append(edge_directions_func(ic, jc))\n",
    "        \n",
    "    hhedge_dirs = torch.from_numpy(np.stack(hhedge_dirs).astype(np.float32))\n",
    "    hhedge_attr = torch.concat([critic_graph_data[(s_, \"to\", d_)]['edge_attr'], hhedge_dirs], axis=-1)\n",
    "    critic_graph_data[(s_, \"to\", d_)]['edge_attr'] = hhedge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aifs.utils.graph_gen import plot_bipartite_from_graphdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bipartite_from_graphdata(\n",
    "    \"H31 to H30 Graph\", \n",
    "    \"blue\",\n",
    "    critic_graph_data[(\"h31\", \"to\", \"h30\")],\n",
    "    ('scoords_rad', 'dcoords_rad'),\n",
    "    critic_graph_data[(\"h31\", \"to\", \"h30\")]['scoords_rad'],\n",
    "    critic_graph_data[(\"h31\", \"to\", \"h30\")]['dcoords_rad']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bipartite_from_graphdata(\n",
    "    \"H32 to H31 Graph\", \n",
    "    \"blue\",\n",
    "    critic_graph_data[(\"h32\", \"to\", \"h31\")],\n",
    "    ('scoords_rad', 'dcoords_rad'),\n",
    "    critic_graph_data[(\"h32\", \"to\", \"h31\")]['scoords_rad'],\n",
    "    critic_graph_data[(\"h32\", \"to\", \"h31\")]['dcoords_rad']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bipartite_from_graphdata(\n",
    "    \"H33 to H32 Graph\", \n",
    "    \"blue\",\n",
    "    critic_graph_data[(\"h33\", \"to\", \"h32\")],\n",
    "    ('scoords_rad', 'dcoords_rad'),\n",
    "    critic_graph_data[(\"h33\", \"to\", \"h32\")]['scoords_rad'],\n",
    "    critic_graph_data[(\"h33\", \"to\", \"h32\")]['dcoords_rad']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bipartite_from_graphdata(\n",
    "    \"ERA to H33 Graph\", \n",
    "    \"blue\",\n",
    "    critic_graph_data[(\"era\", \"to\", \"h33\")],\n",
    "    ('scoords_rad', 'dcoords_rad'),\n",
    "    critic_graph_data[(\"era\", \"to\", \"h33\")]['scoords_rad'],\n",
    "    critic_graph_data[(\"era\", \"to\", \"h33\")]['dcoords_rad']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/ec/res4/hpcperm/syma/gnn/\"\n",
    "\n",
    "fname = f\"gan_critic_graph_mappings_normed_edge_attrs_o{era_res}_h_0_1_2_3.pt\"\n",
    "torch.save(critic_graph_data, os.path.join(output_dir, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltr /ec/res4/hpcperm/syma/gnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-pyg-2.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
